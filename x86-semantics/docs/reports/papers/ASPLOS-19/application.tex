\section{Applications} \label{sec:Appl}

In this section, we illustrate a few applications of our formal semantics, in addition to the reference model mentioned in the previous section.
Our goal here is to demonstrate that our semantics can be used for formal reasoning of \ISA programs for a wide variety of purposes.
For this reason, the applications are illustrative only.
Each application can be leveraged into a standalone tool, with its own user interface, case studies and even reference manual, but this is not our goal here.
In fact, thanks to the language-parametric nature of \K, none of these reasoning approaches can be regarded as novel {\it per se}, because they are already used in the context of other languages defined in \K and their implementation is language-semantics agnostic.
%
We begin with a discussion of a use case for hardware verification.

% All these applications are realized based on the  generic tools offered by the employed \K semantic framework.

% \Qd{Is the placement of application Ok..or we need to place the sym ex example before verification and say something about progressing from simpler to more complex capability}
\cmt{
These application tools are
automatically derived from the semantics and changes made to the
semantics immediately affect the tools. This is as opposed to writing analysis tools 
independently of semantics, which could be error prone and/or difficult to maintain. 
}

%----------------------------------------------------------------------------------------------------------
\subsection{Validating Processor Hardware and Documentation}
\label{sec:Appl:Processor}
%----------------------------------------------------------------------------------------------------------

Verification is considered one of the most (if not the most) important 
challenges in modern processor design, for several reasons: 
(i) the enormous state spaces of modern systems; 
(ii) the lack of formal specifications in the state-of-practice, 
(iii) generating high quality test inputs for simulation, 
(iv) quantifying/analyzing the extent of coverage of simulation, and 
(v) generating a complete set of properties for checking. 
For post-silicon validation, an additional challenge is the difficulty 
of debugging and diagnosing observed erroneous behaviors. 
For all these reasons, verification is estimated to use 70\% of the 
resources and time, while design takes only 30\%~\cite{Foster:DAC2015}.

A fully executable formal ISA-level specification such as the one developed here can improve the state of practice in verification in two significant ways. 

First, it can provide a reliable specification of functional behavior of 
hardware with respect to observable states. This increases 
confidence in the input tests, for both directed and random test generation. 
High confidence tests can reduce time and increase focus during debugging, 
triage and diagnosis efforts. This is especially valuable in post-silicon 
validation, where observability within the chip is very limited, and functional 
validation is a key goal. This method can also help post-silicon failure 
diagnosis by identifying buggy input/output pairs and pinpointing specific 
erroneous output state bits.

Second, since our method can symbolically execute instructions, it can be used 
to generate input tests that have high coverage. While such analyses have been 
done at the detailed RTL level \cite{liu2014, liu2011, mishra18}, we are 
unaware of similar tools at the ISA level. The most significant advantage of 
such symbolic execution is the ability to detect corner case or hard to detect 
bugs~\cite{liu2014}.  (This is analogous to finding security vulnerabilities 
due to corner-case software bugs, illustrated in 
Section~\ref{sec:Appl:Security}, but applied to the hardware implementation instead of software.)  We expect that ISA level symbolic analysis will 
uncover such subtle and complex bugs due to the higher level of abstraction 
and better design perspective than the RTL analyses.

A closely related challenge is checking the accuracy of ISA specifications, including reference manuals.
%
By using such manual specifications to construct a formal specification, we may uncover errors in the manual specifications.
%
This is explicitly demonstrated by the two bugs we discovered in the Intel X86-64 manual, while performing the instruction-level validation tests described in Section~\ref{sec:Eval}.
%
These bugs were discovered as a result of running test cases using both the formal semantics generated by reading the manuals and the hardware, and finding a mismatch, then checking the manual specification  carefully to determine whether the bug lies in the manuals or in the hardware.
%
However, given an existing semantics, a far more valuable strategy would be to \emph{automatically generate human-readable documentation from the formal specification}.
%
A basic version of this strategy is likely quite feasible today, and much more sophisticated versions that synthesize illustrative examples and even explanatory text automatically could be possible soon, given recent advances in concolic test generation, program synthesis, and natural language processing.

In recognition of the many benefits of an executable formal specification, Intel has an internal project to develop such a specification of the X86-64 ISA semantics.
%
We have communicated with the team developing this specification, and we hope to contribute to or assist in their efforts~\cite{Intel:PC2}.

%----------------------------------------------------------------------------------------------------------
\subsection{Program Verification}
\label{sec:Appl:Verification}
%----------------------------------------------------------------------------------------------------------

\input{figures/sum2n.tex}

The \K framework provides a language-parametric, reachability logic theorem prover~\cite{Stefanescu:2016,Rosu:2012}.  We instantiated it with our semantics to generate a correct-by-construction deductive verifier for \ISA programs.
Here, the functional correctness properties are specified as reachability specifications, essentially a pair of pre- and post-conditions for each function.
The derived \ISA verifier uses a sound and relatively complete proof system to prove the given specifications w.r.t.~the \ISA semantics.
Like in other deductive verifiers, the repetitive constructs such as loops and recursive functions need to be annotated with invariants.
The verifier is automatic: it requires only the program, its specification, and the invariants.

% K offers support for program verification based on rule-based
% semantics, at no additional cost (with no need to define another
% semantics)~\cite{Rosu:2012}. Program properties are specified as reachability
% rules. K uses a sound and relatively complete proof system for
% deriving such rules from the operational semantics rules, which
% amounts to:
% \begin{enumerate}
%     \item Performing symbolic execution of code without repetitive behavior
%     using the semantics rules; and
%     \item Reasoning about repetitive constructs (loops, recursion). 
% \end{enumerate}

% Like in Hoare logic, all the repetitive constructs need to be annotated
% with specifications. The verification is automatic: the user only provides
% the specifications. The specifications are given as reachability
% rules between symbolic configurations with constraints 

To demonstrate that our semantics can be used to verify \ISA programs, we use the \ISA verifier to prove the functional correctness of the \s{sum-to-n} program as shown in Figure~\ref{fig:sum2n}.
It takes $N$ as input and returns the sum from 1 to $N$.
% The assembly code of the program, \fig{fig:sum2n}(b), is annotated with comments to show its resemblance with the C code, \fig{fig:sum2n}(a).
The functional correctness can be essentially described as: $\reg{rax} = \sum_1^N n = N (N + 1) / {2}$.
%
We present the actual specification that is fed to the \ISA verifier.
The specification has two parts: the top-level specification and the loop invariant.

% To test the viability of using the generic reachability verification
% infrastructure with the \ISA semantics, we verified the functional correctness of a  simple  ``sum from $1$ to $n$'' program as shown in Figure~\ref{fig:sum2n}.  We use this program as a demonstration of the capability of our model to reason high level properties about programs. The assembly language version  of the program, \fig{fig:sum2n}(b), is annotated with comments to show its resemblance with the C-version on the left, \fig{fig:sum2n}(a).

% The high level property that we intend to proof is that the at program point 26 the value of \reg{rax} is given by: 
% $$\reg{rax} = \sum_{i = 1}^N i = \frac{N * (N + 1)}{2}$$




% Next,  we present the \K specification rules uses to proof the the property. It consists of  two reachability rules: (1) Main rule stating the functional correctness of the program as a whole; and (2) The  loop invariant rule stating the functional correctness of the loop.

% Note that the program behaves incorrectly/unexpectedly if arithmetic overflow occurs during its execution. One challenge in verifying this program is to identify the conditions under which overflow does not occur. 

\begin{figure}[t]
\begin{lstlisting}[style=KRULE]
<regstate>... 
    "RDI" |-> 64'N
    "RBP" |-> 64'56
    "RIP" |-> (64'0 => 64'-1) 
    "RAX" |-> (64'_ => 64'(N * (N + 1)) / 2)
...</regstate>
<memstate>...
    // -8(%rbp): n
    48 |-> byte(0, _) => byte(0, 32'0)
    49 |-> byte(0, _) => byte(1, 32'0)
    50 |-> byte(0, _) => byte(2, 32'0)
    51 |-> byte(0, _) => byte(3, 32'0)
    // -4(%rbp): s
    52 |-> byte(0, _) => byte(0, (32'(N * (N + 1)) / 2))
    53 |-> byte(0, _) => byte(1, (32'(N * (N + 1)) / 2))
    54 |-> byte(0, _) => byte(2, (32'(N * (N + 1)) / 2))
    55 |-> byte(0, _) => byte(3, (32'(N * (N + 1)) / 2))
...</memstate>
    requires N >= 0 and N < 2^31
         and (N * (N + 1)) / 2 < 2^31
\end{lstlisting}
\begin{center}
\vspace{-10pt}
{\small (a) Top-level specification
%\Comment{s is a signed int, so result should be less than $(2^{31} -1)$?  Or make s unsigned in C source.}
}
\vspace{-5pt}
\end{center}
% \caption{Specification of \s{sum-to-n} program}
% \label{fig:main-rule}
% \end{figure}
% \begin{figure}[t]
\begin{lstlisting}[style=KRULE]
<regstate>... 
    "RIP" |-> (L3 => L2)
...</regstate>
<memstate>...
    // -8(%rbp): n
    48 |-> byte(0, A) => byte(0, 32'0)
    49 |-> byte(1, A) => byte(1, 32'0)
    50 |-> byte(2, A) => byte(2, 32'0)
    51 |-> byte(3, A) => byte(3, 32'0)
    // -4(%rbp): s
    52 |-> byte(0, B) => byte(0, 32'(B + A * (A + 1) / 2))
    53 |-> byte(1, B) => byte(1, 32'(B + A * (A + 1) / 2))
    54 |-> byte(2, B) => byte(2, 32'(B + A * (A + 1) / 2))
    55 |-> byte(3, B) => byte(3, 32'(B + A * (A + 1) / 2))
...</memstate>
    requires A >= 0 and A < 2^31
         and B >= 0 and B < 2^31
         and B + ((A * (A + 1)) / 2) >= 0  
         and B + ((A * (A + 1)) / 2) < 2^31
\end{lstlisting}
\begin{center}
\vspace{-10pt}
{\small (b) Loop invariant}
\vspace{-5pt}
\end{center}
% \caption{Loop Invariant Rule. X and Y denote concrete code memory addresses corresponding to instructions at loop header (at line 10) and following the loop (at line 25) resp.}
% \label{fig:loop-invariant}
\caption{Specification of \s{sum-to-n} program}
\label{fig:sum-to-n-spec}
\end{figure}




% \paragraph{Top-Level Specification}

Figure~\ref{fig:sum-to-n-spec}(a) shows the functional correctness specification of the \s{sum-to-n} program.
The \s{regstate} cell specifies the relevant registers used in the program, omitting the irrelevant ones denoted by ``...''.
Specifically, it specifies that \reg{rdi} holds the value $N$ without being updated during the program execution, and \reg{rax} will have the expected return value.
The \s{memstate} cell specifies the relevant part of the memory omitting others (denoted by ``...'').
It specifies the stack memory addresses \s{-8(\%rbp)} and \s{-4(\%rbp)} corresponding to \m{n} and \m{s}, respectively.
The \m{requires} clause specifies the condition of $N$ that prevents the arithmetic overflow.
% The program counter \reg{rip} starts from $0$ (the code memory address) and ends at the return address (which we specify using $-1$).
% The first part of the rule is largely static, which means that the contents of configuration cells are not going to change during execution and is given by the \K specifications as follows:
% which essentially represents the initial values of \reg{rdi} and \reg{rbp} and the fact that these values will remain the same throughout the program execution.
%
% The second part consist of the main claim states the following
% \begin{itemize}
%     \item The progarm counter \reg{rip} starts from $0$ (the code memory address corresponding to the instruction at line 2) and ends at the return address( which we specify using $-1$).
%     \item The stack memory address \s{-4(\%rbp)}, which intends to store the value of sum, starts with ``don't care'' state  and ends with the correct sum. 
%     \item The stack memory address \s{-8(\%rbp)}, which intends to store the value of $n$ for comparison purpose, starts with ``don't care'' state  and ends with $0$. 
%     \item The value of $N$ is such that overflow will not occur during execution.     
% \end{itemize}
% and is specified using the following \K rules:
% \paragraph{Loop Invariant}
Figure~\ref{fig:sum-to-n-spec}(b) shows the loop invariant specification.
It specifies the behavior of an arbitrary loop iteration.
That is, assuming the values of \m{n} and \m{s} be $A$ and $B$, resp., in the beginning of an arbitrary loop iteration, it specifies their final values in the end of the entire loop execution, which are 0 and $B + A(A+1)/2$, respectively.
Note that when $A = N$ and $B = 0$, i.e., the first loop iteration, the loop invariant captures the entire loop behavior.

% The static part of this rule is same as the main claim.  
% The non-static part specifies the behavior of the program any time it reaches the loop head (line 8, Figure~\ref{fig:sum2n}). The behavior can be  specified informally as:
% \begin{itemize}
%     \item The program counter starts and ends at code memory addresses corresponding to instruction at line 10 and  25 respectively.
%     \item The stack memory address \s{-4(\%rbp)}, which intends to store the value of sum, starts with a partial sum \s{B}  and ends with the correct sum.   
%     \item The stack memory address \s{-8(\%rbp)}, which intends to store the value of $n$ for comparison purpose, starts with non zero positive value \s{A}  and ends with $0$.  
%     \item \s{A} and \s{B} are sufficiently low that overflow will not occur during execution.
% \end{itemize}
% and  in terms of \K specifications as:




The \K verifier takes a minute to verify the \m{sum-to-n} assembly code satisfies the functional correctness specification.

% The overall verification took approx. 60 secs. We believe that our preliminary evaluation delivers a realistic potential of using the semantics for \ISA program verification. \revisit{about the library/lemmas to assst reasoning about bitvectors}



\subsection{Finding Security Vulnerabilities}\label{sec:Appl:Security}

\K automatically derives a correct-by-construction symbolic execution engine from the given semantics.
Being instantiated with our semantics, the engine can be used to symbolically execute and explore all possible paths in the given \ISA program.
In this section, we demonstrate how this capability can be used to find a  security vulnerability.
In practice, this capability would be used more efficiently than exhaustive path exploration by using Dynamic Symbolic Execution~\cite{godefroid_automated_2008}.

\input{figures/histarbug.tex}

Consider the code snippet of the HiStar~\cite{HiStar:2006} kernel, as shown in Figure~\ref{fig:histar}(a), in which the KLEE~\cite{Cadar:2008} team found a security vulnerability.
The \s{safe\_addptr} function is supposed to compute the sum of two arguments \m{a} and \m{b}, setting the flag argument \m{of} when the arithmetic overflow occurs during the addition.
That is, one of the functional correctness properties is that ``$\m{*of} = 1$ if $\m{a} + \m{b} > \m{r}$'', where $+$ is the mathematical addition (with no overflow).
The functional correctness, however, is not satisfied when the source code is compiled to a 32-bit target,
% as shown in Figure~\ref{fig:histar}(b),
since the size of \m{r} becomes 32-bit (\m{uintptr\_t}) while the sizes of \m{a} and \m{b} are still 64-bit (\m{uint64\_t}).\footnote{The function call \s{safe\_addptr(*of, address, size)} is used to validate that an user is allowed to access the memory range specified by the arguments \s{address} and \s{size}.
The access is denied if an overflow occurs.
A bug in the overflow detection might be exploited by an attacker to gain an access to a memory region beyond the control of the running process.}
A suggested fix~\cite{Cadar:2008} is to change the conditional expression from \m{r < a} to \m{r < a || r < b}.

Using the symbolic execution engine derived from our semantics, we could find that, in the assembly code as shown in Figure~\ref{fig:histar}(b), there exists a path that reaches \m{L2} (i.e., the else branch) even if the addition overflow occurs.
The (simplified) path condition provided by the symbolic execution engine is:
\[
\m{a} + \m{b} \ge 2^{32}
~~\wedge~~
(\m{a} + \m{b} \mod 2^{32}) \ge \m{a}
\]
where $0 \le \m{a} < 2^{64}$ and $0 \le \m{b} < 2^{64}$.
We asked Z3 to solve the above path condition and it returned a solution (i.e., a concrete input to trigger the security vulnerability): \m{a} = \m{0x00000000ffffffff} and  \m{b} = \m{0xffffffff00000000}.



% TODO: we can add this if we have enough space.
% \begin{figure}[t]
% \begin{lstlisting}[style=KRULE,numbers=left, numberstyle=\tiny\color{codegray}]
% <regstate>...
%     "RIP" |-> (mi(64, 0) => L2)
%     "RBP" |-> (mi(64, 56))
% ...</regstate>
% <memstate>... 
%   // -8(%rbp): a
%   40 |-> (byte ( 0 , mi(64, B)))
%   41 |-> (byte ( 1 , mi(64, B)))
%   42 |-> (byte ( 2 , mi(64, B)))
%   43 |-> (byte ( 3 , mi(64, B)))
%   44 |-> (byte ( 4 , mi(64, B)))
%   45 |-> (byte ( 5 , mi(64, B)))
%   46 |-> (byte ( 6 , mi(64, B)))
%   47 |-> (byte ( 7 , mi(64, B)))
%   // -16(%rbp): b
%   48 |-> (byte ( 0 , mi(64, A))) 
%   49 |-> (byte ( 1 , mi(64, A))) 
%   50 |-> (byte ( 2 , mi(64, A))) 
%   51 |-> (byte ( 3 , mi(64, A))) 
%   52 |-> (byte ( 4 , mi(64, A))) 
%   53 |-> (byte ( 5 , mi(64, A))) 
%   54 |-> (byte ( 6 , mi(64, A))) 
%   55 |-> (byte ( 7 , mi(64, A))) 
% ...</memstate>
%     requires  A >= 0 and A < 2 ^Int 64 
%         and   B >= 0 and B < 2 ^Int 64 
%     // check if the oerflow condition is true.
%     ensures   A + B >= 2 ^ 32
% endmodule
% \end{lstlisting}
% \caption{Specification used to do symbolic execution on code snippet at Figure 7.}
% \label{lst:CSHISTAR}
% \end{figure}




% symbolically executed the assembly code
% in Figure~\ref{fig:histar}(b) to explore all possible paths and find 



% Symbolic execution is straightforward to achieve using \K framework because exactly the  same semantics rules applied for both concrete  and symbolic execution. While doing symbolic execution, the applied semantics rules constraint the symbolic terms which are then solved using \Z~\cite{DeMoura:2008} (which is incorporated in K). 

% \cmt{ 
% written o work with concrete terms
% using a rewriting-based semantics:
% whether a term is concrete or abstract makes no difference to the
% theory. Rules designed to work with concrete terms needs no change in order to work with symbolic terms. The symbolic terms being mathematical variables could be constrained.
% }


% while $\m{a} + \m{b} \ge 2^{32}$ where $+$ is the mathematical addition.


% While the functional correctness is satisfied when the source code is compiled to a 64-bit target, it is not for a 32-bit target.


% The security bug is found and reported by the developer's of KLEE~\cite{Cadar:2008} while doing symbolic execution on $32$-bit of the HiStar~\cite{HiStar:2006} kernel.



% Figure~\ref{fig:histar}(a) shows the C source code of the problematic function \m{safe\_addptr}.

% Figure~\ref{fig:histar}(a) presents the code for the function containing the bug. The function \s{safe\_addptr}
% \footnote{\s{safe\_addptr(*of, address, size)} is used to validate if user is allowed to  access a memory range as specified by the arguments `address' and `size'. In case of overflow, access is denied. A bug in the overflow detection check might be exploited by an attacker to gain access to memory regions beyond the control of running process.}
%     \cmt{ 
%      function is used for validating the user memory address by taking as argument an address and a size in order to compute if the user is allowed to access the memory in that range. The routine uses the overflow to prevent access when a computation could overflow. Failure to do so might allows a malicious process to gain access to memory regions outside its control.} is supposed to check if the addition overflows. If true, then the control reaches ``error state'' and return after setting \s{*of} to true. Otherwise, control reaches ``safe state'' and return.
%      The function arguments being $64$-bit long, the test condition used is not sufficient (it should be (r < a) || (r < b)) and can fail to indicate overflow for large values of b. 

% Figure~\ref{fig:histar}(b) shows a $32$-bit compiled version of the assembly program   corresponding to the C-code on the left. The assembly code is simplified for brevity reasons. Our approach to unravel the bug is to try driving the program to a state such that 1. The program counter is at ``safe state'', and 2. The addition result  overflows. If we are successful, then we found the bug. Listing~\ref{lst:CSHISTAR} is the specification for the same; Line 5  specifies  the first requirement and line 33 ensures the second.  



% A symbolic execution on the code snippet at \fig{fig:histar} drives us to the required state demanded by the specification above. Upon solving the accumulated constrains (at program point corresponding to ``safe state'') using \Z, we can get a concrete input, $\mathtt{a = 0x00000000ffffffff}$ and  $\mathtt{b = 0xffffffff00000000}$, which can trigger the bug.



\subsection{Translation-Validation of Optimizations}


\begin{figure}[t]
\begin{lstlisting}[language=C++,basicstyle=\scriptsize,keywordstyle=\color{blue}]
  int popcnt(uint64_t x) {
    int res = 0;
    for (; x > 0; x >>= 1) { res += x & 0x1ull; }
    return res;
  }
\end{lstlisting}
\caption{\s{popcnt} program}
\label{fig:popcnt}
\end{figure}


\K also provides a program equivalence checker that can be used for the translation-validation of compiler optimizations.
We derived an \ISA program equivalence checker from our semantics and used it to validate different optimizations.
Figure~\ref{fig:popcnt} shows a program that we considered, \s{popcnt}, which counts the number of set bits in the given input.

We compiled the program with different optimizations: the GCC compiler optimizations (-O0, -O1, -O2, and -O3), and the Stoke super-optimization.
On top of the baseline (-O0), the -O1 optimization produces a code obtained by performing the mem2reg optimization, the -O2 optimization produces one by factoring out the common statement over different branches,\footnote{Specifically, by performing the common subexpression elimination, followed by certain statement reordering optimization, followed by the strength reduction.} and the -O3 optimization produces the same code with -O2. The Stoke super-optimization translates the assembly code into a single instruction: \instr{popcnt \%rdi, \%rax}, where \reg{rdi} and \reg{rax} correspond to the input and the return values, resp.

We validated these optimizations by checking the equivalence between the optimized programs.
The equivalence checker symbolically executes each program and compares their return values (i.e., the symbolic expression of the \reg{rax} register value) using Z3.
It is able to prove successfully that all optimization variants are equivalent, i.e., to check the correctness of all these optimizations on \s{popcnt}.

Note that the symbolic execution of the \s{popcnt} program does not require an additional annotation about the loop because the number of loop iterations is bound to a constant (i.e., the bit-size of the input, 64).
In general, however, the equivalence checker may require us to provide an additional annotation about loops, which can be automatically generated by augmenting the underlying compiler.




% \subsection{Program Equivalence Checker across Optimization}

% The aplication we showcase here is to proof equivalence of \ISA programs across optimizations. For presentation, we chose a program (\fig{fig:countone}(a)) which counts the number of set bits in a $64$-bit integer.
% \input{figures/countOne.tex}
% We compiled the program using different GCC optimizations \s{-O$0$/-O$1$/-0$3$} (The output of \s{-0$2$} and \s{-O$3$} are exactly  same) and symbolically execute the resulting \ISA programs using symbolic value of \s{x}. Note that the reasoning about the loop termination, which took $24$ secs, is fully automatic and is facilitated by \K's matured bit-vector theory support. Figure~\ref{fig:countone}(b) shows the relevant lemmas used for loop reasoning. \footnote{As evident from the lemmas that the loop will be iterated $64$ times before termination and hence the reason of longer time.  Runtime can be improved by adding loop invariants.} 

% Using \Z, we pairwise matched the SMT formula corresponding to \reg{rax} (used as program return value) which is accumulated at the end of the execution. As expected, all the formulas are equivalent. Also, we employed \Stoke super-optimizer to further optimize the program generated by GCC (\s{-O3}), which produces the optimal rewrite with \instr{popcnt \%rdi, \%rax}. We used symbolic execution as above to  prove its equivalence to the other variants.        


